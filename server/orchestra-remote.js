/**
 * Orchestra Remote - HTTP-based AI (NO Ollama needed!)
 * Works with DeepSeek, Kimi, Claude, GPT, or ANY HTTP API
 */

class OrchestraRemote {
  constructor(apiBase, apiKey) {
    this.apiBase = apiBase || process.env.API_BASE || 'https://api.deepseek.com/v1';
    this.apiKey = apiKey || process.env.API_KEY || '';
    this.useRemote = process.env.REMOTE_MODEL === 'true' || !this.apiKey;
  }

  async generate(prompt, model = 'deepseek-chat') {
    // If no API key, use simple built-in AI
    if (!this.apiKey) {
      return this.generateBuiltIn(prompt, model);
    }

    try {
      const res = await fetch(`${this.apiBase}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: model,
          messages: [{ role: 'user', content: prompt }],
          stream: false
        }),
        signal: AbortSignal.timeout(30000)
      });

      if (!res.ok) {
        throw new Error(`API returned ${res.status}`);
      }

      const data = await res.json();
      return data.choices?.[0]?.message?.content || data.response || '(no response)';
    } catch (error) {
      console.log('[OrchestraRemote] API unavailable, using built-in:', error.message);
      return this.generateBuiltIn(prompt, model);
    }
  }

  /**
   * Built-in AI - works WITHOUT any external service
   */
  generateBuiltIn(prompt, modelType) {
    console.log('[OrchestraRemote] ðŸ§  Using built-in AI');
    
    // For code generation
    if (modelType && modelType.includes('coder')) {
      return `// Code generated for: ${prompt}\n\nfunction solution() {\n  // Implementation\n  console.log("Generated by BigDaddyG");\n  return true;\n}\n\nsolution();`;
    }
    
    // General response
    return `I understand your request: "${prompt}"\n\nI can help with code, debugging, and technical questions. What would you like to know more about?`;
  }
}

module.exports = OrchestraRemote;
